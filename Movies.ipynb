{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import re\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nLEGEND:\\nr = request\\ns = soup\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "LEGEND:\n",
    "r_ = request\n",
    "s_ = soup\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function scraps synopsis and original title\n",
    "def scrap_synopsis(title_id):\n",
    "    # 1. Create working link to a movie. Combingin constant imdb url with title ID : '/title/ID/'\n",
    "    movie_url = 'https://www.imdb.com'+title_id\n",
    "    # 2. Link that leads to synopsis\n",
    "    plot_url = 'plotsummary?ref_=tt_stry_pl#synopsis'\n",
    "    # 3. Create working synopsis link and get request model\n",
    "    r_synopsis = requests.get(movie_url + plot_url).text\n",
    "    # 4. Use soup to parse synopsis html object\n",
    "    s_synopsis = BeautifulSoup(r_synopsis, 'html.parser')\n",
    "    # 5. Extract synopsis text\n",
    "    synopsis = s_synopsis.find('ul', id='plot-synopsis-content').li.text\n",
    "    \n",
    "    # Scrapping original title. If basic title = original it creates error. Get basic title.\n",
    "    try:\n",
    "        r_title = requests.get(movie_url).text\n",
    "        s_title = BeautifulSoup(r_title, 'html.parser')\n",
    "        original_title = s_title.find_all('div', class_='originalTitle')[0].text\n",
    "        original_title = re.sub(' \\(original title\\)', '', original_title)\n",
    "    except:\n",
    "        original_title = s_title.find_all('div', class_='title_wrapper')\n",
    "        original_title = re.search(r'[^\\xa0]*',original_title[0].h1.text).group()\n",
    "    \n",
    "    return synopsis, original_title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title_ids = []\n",
    "titles = []\n",
    "years = []\n",
    "ratings = []\n",
    "votes = []\n",
    "\n",
    "for page_counter in range(0,251,50): # Looping over next pages in top 250\n",
    "    # 1. Get request model of top 250 imdb movies and convert it to str with .txt\n",
    "    r_top250 = requests.get(f'https://www.imdb.com/search/title/?groups=top_250&view=simple&sort=year,desc&start={page_counter}').text\n",
    "    # 2. Use soup to parse html object\n",
    "    s_top250 = BeautifulSoup(r_top250, 'html.parser')\n",
    "\n",
    "    # Scrapping title ID\n",
    "    for div in s_top250.find_all('div', class_='col-title'):\n",
    "        for link in div.find_all('a'):\n",
    "            title_ids.append(link.get('href'))\n",
    "            titles.append(link.text)\n",
    "\n",
    "    # Scrapping year    \n",
    "    for span in s_top250.find_all('span', class_='lister-item-year text-muted unbold'):\n",
    "        year_str = span.text\n",
    "        year = re.search('\\d\\d\\d\\d',year_str).group()\n",
    "        years.append(int(year))\n",
    "\n",
    "    # Scrapping rating and votes\n",
    "    for div in s_top250.find_all('div', class_='col-imdb-rating'):\n",
    "        for strong in div.find_all('strong'):\n",
    "            s = re.split(' ', strong.get('title'))\n",
    "            ratings.append(s[0])\n",
    "            votes.append(int(s[3].replace(',',''))) # Converting comma separated string to int ('115,334' = 115334)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating DataFrame from previous elements\n",
    "movies = pd.DataFrame({'ID':title_ids, 'Title':titles, 'Year':years, 'Rating':ratings, 'Votes':votes})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scrapping plots and original titles into a list\n",
    "plots = []\n",
    "original_titles = []\n",
    "for i,t in enumerate(movies[movies['Year'] >= 2004]['ID']):\n",
    "    print(len(movies[movies['Year'] >= 2004]['ID'])-i) # Printing counter and clearing output in the end\n",
    "    plot, title = scrap_synopsis(t)\n",
    "    plots.append(plot)\n",
    "    original_titles.append(title)\n",
    "    clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding two columns\n",
    "movies.insert(2, 'Original Title', pd.Series(original_titles))\n",
    "movies['Plot'] = pd.Series(plots)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting movies released after 2004 since Google trends dates back to 2004\n",
    "movies2004 = movies[movies['Year'] >= 2004]\n",
    "# Setting None value where there was no synopsis available on IMDB\n",
    "movies2004['Plot'] = movies2004['Plot'].apply(lambda x: None if 'looks like we don\\'t have' in x else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving both dataframes to csv\n",
    "movies2004.to_csv('movies2004.csv')\n",
    "movies.to_csv('movies.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
